<!DOCTYPE html>
<html lang="en" class="h-100">
<head>
    <!-- Required meta tags -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- Bootstrap CSS -->
    <link href="css/bootstrap.css" rel="stylesheet">
    <!-- Custom CSS -->
    <link href="css/custom.css" rel="stylesheet" >

    <title>Mingfei Cai | Homepage</title>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-159321666-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-159321666-1');
    </script>
</head>

<body>

    <nav class="navbar navbar-expand-lg navbar-dark bg-dark" aria-label="navbar-main", style="opacity: 1">
        <div class="container">
            <a class="navbar-brand" href="index.html">Mingfei Cai</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarsExample07" aria-controls="navbarsExample07" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
    
            <div class="collapse navbar-collapse" id="navbarsExample07">
                <ul class="navbar-nav me-auto mb-2 mb-lg-0">
                    <li class="nav-item">
                        <a class="nav-link" href="index.html">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link active" aria-current="page" href="literature.html">Literature</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link disabled">Life</a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>


<div class="container-fluid">
    <div class="row py-5 justify-content-center">
        <div class="col-12 text-center fs-5">
            <h1>
                Literature Notes
                <small class="text-muted">About Human Mobility</small>
            </h1>
            <p class="lead">
                This is my note page for the papers about the human mobility
            </p>
        </div>

        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Transfer Urban Human Mobility via POI Embedding over Multiple Cities </p>
                <p class="fw-light lh-1"> ACM/IMS Transactions on Data Science, December 2020</p>
                <span class="badge bg-success">Trajectory Prediction</span>
                <span class="badge bg-info text-dark">Embedding</span>
                <span class="badge bg-primary">POIs</span>
                <span class="badge bg-secondary">LSTM and CNN</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The basic task is to predict the next position given a trajectory sequence (prediction task).
                    Fusing GPS and POI data, the paper proposed image-like embedding of POIs to represent a trajectory like an artificial video.
                    This enables transfer learning to exploit other cities with limited observation data. 
                    An LSTM-on-CNNs architecture is designed to capture both spatio-temporal and geographical information.
                </p>
                <p class="text-body fw-light lh-3" style="text-align: justify">
                    One tricky and interesting point for me is the construction of POI-image. 
                    Different POI categories serve as different channels, while the value of a pixel is the number of POI of one category in one mesh (It means that all pixel values will not change along the time). 
                    Trajectories are used as capture frame (location meshes + window meshes) to generate the video clips. 
                    The main intuition is to mine sequential relationships of POIs.
                    One potential problem in my opinion is the inefficient use of the expensive trajectory data.
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> City2City: Translating Place Representations across Cities </p>
                <p class="fw-light lh-1"> ACM SIGSPATIAL 2019</p>
                <span class="badge bg-success">Trajectory Prediction</span>
                <span class="badge bg-info text-dark">Embedding</span>
                <span class="badge bg-secondary">LSTM</span>
                <span class="badge bg-dark">Transfer Learning</span>


                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The background is location prediction task given trajectory history in this paper. 
                    The place representation matrix is obtained from an LSTM-RNN using stay point sequences generated from GPS data. 
                    All three proposed models are based on this representation. 
                    The most preferred model is to train a transformation function to map representation in the common vector space. 
                    The author also develops another two models for comparison. 
                    One is simply merging mobility data from two cities and training representation together. 
                    Another is to train the adversarial model.
                </p>
                <p class="text-body fw-light lh-3" style="text-align: justify">
                    Due to the unsupervised learning setting, the paper uses the top-N visited place pairs to train the mapping function, which may be problematic in my opinion. 
                    Moreover, the representation matrix deal with embeddings of stay points, which may be expensive and difficult to learn an accurate mapping function.
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> CityCoupling: Bridging Intercity Human Mobility </p>
                <p class="fw-light lh-1"> Ubicomp 2016</p>
                <span class="badge bg-success">Irregular Trajectory Prediction</span>
                <span class="badge bg-dark">Transfer Learning</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The paper utilizes an expectation-maximation (EM) algorithm to estimate intercity spatial mapping. 
                    The intercity trajectory matching is seen as latent variables and the intercity spatial mapping as the parameters. 
                    Then, a Gibbs sampling multiple hidden Markov model utilizes the Viterbi algorithm to generate simulated trajectories using the generated spatial mapping. 
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    In my opinion, even though the idea of not using any prior knowledge is fascinating, simply matching trajectories and estimating optimal parameters can be computationally expensive and difficult to converge. 
                    And this process may neglect underlying patterns.
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> A Non-Parametric Generative Model for Human Trajectories </p>
                <p class="fw-light lh-1"> IJCAI 2018</p>
                <span class="badge bg-success">Trajectory Simulation</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The paper proposes a non-sequential non-parametric generative model to capture high-order geographic and semantic features of human mobility. 
                    It uses the matrix to represent one discretized location and each cell contains information about the time and duration of visiting that cell in the given trajectory. 
                    The third dimension of the matrix (tensor) is the repeated times of visiting the same location. The paper uses the generative adversarial networks to train the model.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The idea of non-parametric is very fascinating since it is difficult to find a comprehensive and sound approach to model the human mobility. 
                    The proposed method “compresses” the time dimension. 
                    However, it also sacrifices the ability of explaining the patterns in human knowledge.
                </p>

            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> DeepMove: Predicting Human Mobility with Attentional Recurrent Networks </p>
                <p class="fw-light lh-1"> WWW 2018</p>
                <span class="badge bg-success">Trajectory Prediction</span>
                <span class="badge bg-info text-dark">Embedding</span>
                <span class="badge bg-warning text-dark">Multimodal</span>
                <span class="badge bg-secondary">RNN and Attention</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The task of human mobility is the prediction task. 
                    The paper constructs multimodal embeddings for current and historical trajectories. 
                    Then the embeddings are fed into a Recurrent Neural Network. 
                    A historical attention module between historical and current trajectories is used to capture multilevel periodicity. 
                    The paper proposes two different attention candidate generators: one is to directly embed records into independent latent vectors and sample for candidates, while another is to sequentially encode and take intermediate outputs as candidates. 
                    The workflow of architecture dealing with sequential data is typical. One interesting point is that the paper examines the attention matrix to explain the effectives. 
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    However, in my opinion, the explanation is shallow since it only focuses on the maximum weight to prove it. 
                    More elaborations are needed in this part. 
                    Moreover, even though the author uses multimodal embeddings, the multimodal information is just location, user ID and time, which may not be so powerful. 
                    And conversion from one-hot vectors to dense vectors may be unable to capture complicated features.                   
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Fine-Grained Urban Flow Prediction </p>
                <p class="fw-light lh-1"> WWW 2021</p>
                <span class="badge bg-success">Flow Prediction</span>
                <span class="badge bg-info text-dark">Embedding</span>
                <span class="badge bg-primary">POIs</span>
                <span class="badge bg-secondary">CNN and GCN</span>
                <span class="badge bg-warning text-dark">Multimodal</span>


                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The task of the paper is the prediction of urban flow based on historical data. 
                    The resolution is high (The grid size is ~150m), which is called as fine-grained. 
                    The author selects key timesteps as closeness, period and trend (recent, daily and weekly) to create different layers of the flow inputs, and uses non-shared convolutional layer to process them. 
                    The external factors (like weather and time) and POI information are processed by the meta learner. 
                    All four layers are concatenated and fed into a network to get high-dimensional embeddings for each grid. 
                    To reduce the parameters due to the fine-grained settings, the author develops region partition and uses a Graph Neural Network to consider global spatial dependencies and make predictions.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    In all, it is a very good paper for the comprehensive use of mobility data and the consideration of the external factors as embeddings. 
                    The paper gives a very clear description of the architecture. 
                    One of problem in my opinion is the usage of fine-grained data, as it is expensive and easy to violate privacy. 
                    Moreover, the setting of GCN may be not convincing because the complete graph may not describe the actual connections between different regions.                  
                </p>

            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting </p>
                <p class="fw-light lh-1"> IJCAI 2018</p>
                <span class="badge bg-success">Traffic Prediction</span>
                <span class="badge bg-secondary">Graph and Convolution</span>


                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    This work focuses on the traffic prediction (attributes of the traffic flow like velocity). 
                    The paper constructs graphs directly based on connectivity of observation stations. 
                    An approximation is applied for layer-wise linear structure to reduce parameters. 
                    The author purely uses convolutional networks to build the model. 
                    The spatial features are attained by convoluting on graph structure data, while the temporal features are gathered by applying 1-D convolution layer along the time axis. 
                    The spatial and temporal layers are jointly process using “sandwich” structure.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The paper develops a general approach to process Spatio-temporal sequences. 
                    The math part of approximation is a little bit difficult for me. 
                    And the mining of graph structure a little bit too simple, as the author mainly focuses on balancing spatial and temporal layers.
                </p>

            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Competitive Analysis for Points of Interest </p>
                <p class="fw-light lh-1"> ACM SIGKDD 2020</p>
                <span class="badge bg-info text-dark">Embedding</span>
                <span class="badge bg-primary">POIs</span>
                <span class="badge bg-secondary">GNN</span>
                <span class="badge bg-warning text-dark">Multimodal</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The target is to study competitive relationships of POIs. 
                    The author summarizes POIs and construct graphs (which means generation of edges between POIs) in two aspects. 
                    First is the spatial relationship through heat maps. 
                    Second is the aspect relationship extracted from reviews and search histories. 
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    Then these two graphs are fed into the network to predict competitive relationships through spatial and knowledge sides. 
                    For the spatial side, to consider two spatial factors, different location sectors and distance, the paper designs different convolution layers for different sectors and an attentive propagation layer by assigning distance into different buckets. 
                    Moreover, the competitive and compensative graphs are operated separately and concatenated in the end. 
                    For the knowledge side, the brand and aspect embeddings are learned using specific aggregation functions. 
                    Brands and Aspects are interacted by cross attention.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The interesting point of the paper is usage of multinomial data, including reviews, search histories and spatial relationship of POIs. 
                    How they convert POIs into graph structure is also a good point to consider different factors hierarchically. 
                    Even though the paper is not about mobility using POI information, it is a good hint for delineation of POI interactions.
                </p>
            </div>
        </div>

        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Learning to Simulate Human Mobility </p>
                <p class="fw-light lh-1"> ACM SIGKDD 2020</p>
                <span class="badge bg-success">Trajectory Simulation</span>
                <span class="badge bg-info text-dark">Embedding</span>
                <span class="badge bg-secondary">GAN, CNN and Attention</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The paper introduces a model-free generative adversarial framework to simulate human mobility. 
                    For the generator, it embeds time and location from one hot vector. 
                    Then it projects the dense representation vector into three vectors to enable self-attention. 
                    Three region-based matrices using physical distance, function similarity and historical transition are used to deal with intermediate output to select information. 
                    This information adds the intermediate vector and serves as the final result, just like the residual connection. 
                    Discriminator is convolution-neural-network based. 
                    It converts the trajectory to the 2D feature matrix and convolutes over the matrix. 
                    Besides, it uses the last version of generator as the assistant to complete the partial trajectory. 
                    The loss function cares the distance and regularity. As a result, the travel distance between transition is limited, and same visited locations at the same time are encouraged. 
                    The author also pretrains the model. 
                    Next location prediction is used to pretrain the generator, and the binary classification task whether trajectories exhibit regularities is used to pretrain the discriminator.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The paper balances the model-based and model-free methodology. 
                    It is of great importance to achieve the performance and explanation of model at the same time. 
                    For the mobility patterns, the paper considers the distance, POI distribution, transition and regularities, which may not be comprehensive to explain complicated patterns. 
                    The essential time factors (which mean the absolute time the activities happen) are also neglected. 
                    Unfortunately, the code has not been released, even though they said they would do two years ago.              
                </p>

            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> A Review of Location Encoding for GeoAI: Methods and Applications </p>
                <p class="fw-light lh-1"> International Journal of Geographical Information Science, 2022</p>
                <span class="badge bg-danger">Review</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The paper reviews the location encoding, which is useful for many downstream tasks. 
                    Different encoding methods have different properties, such as distance preserving, direction aware, multi-scale, and parametric or not. 
                    The choice of encoding needs to consider tradeoff between bias (restricted hypothesis space) and variance (flexible and large hypothesis space). 
                    Based on different input data, encoders have different properties. 
                    The paper mainly reviews single point location encoders receive point coordinates and diversify in whether consider neighbors or not in the space. 
                    It also briefly introduces encoders for polyline, polygon and raster data.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    In my opinion, even though the distance and direction are intuitive properties the location encoders should maintain, 
                    there is doubt that whether it is necessary as other factors such as high-speed transportation may reduce the influence of distance. 
                    However, there is no denying that the location encoders need to be unified under the same framework to enable the interpretability and transfer learning.
                </p>
            </div>
        </div>

        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> A Survey on Deep Learning for Human Mobility </p>
                <p class="fw-light lh-1"> ACM Computing Surveys, 2021</p>
                <span class="badge bg-danger">Review</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The paper divides mobility tasks into next-location/flow predictions and flow/trajectory generations. 
                    It defines the different problems, lists related datasets as well as evaluation metrics and summarizes diversified deep learning architecture from various papers. 
                    The paper states key points of different settings. 
                    For next-location predictions and trajectory predictions, which are both for agent-level, 
                    the individual spatial and temporal patterns, including regular and irregular mobility, 
                    the external factors and user preferences need to be maintained. 
                    For crowd flow prediction, spatial patterns including influence of near-by and distant areas, 
                    temporal patterns including periodic, trends, recent ones (defined by different period lengths) and external factors need to be considered. 
                    However, for flow generation, only spatial patterns and geographic characteristics (similar to user preference on individual level) are needed. 
                    In the end, the paper also concludes challenges for human mobility problems, 
                    which are geographic transferability, explainability, privacy, tunability and consideration of interactions.</p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    This review paper clarifies the definition of human mobility problems and key points for the solutions, which is of great significance. 
                    It also throws light on the difficulties that future research needs to overcome, with which I completely agree.
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Urban Computing: Concepts, Methodologies, and Applications </p>
                <p class="fw-light lh-1"> ACM TIST 2014</p>
                <span class="badge bg-danger">Review</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The paper gives a review of the urban computing. 
                    It introduces the concept of urban computing, categorizes the applications of urban computing into several groups, introduce the data form and structure used in this domain.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    This paper is the ancestor of the urban computing.
                </p>
            </div>
        </div>

        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Graph WaveNet for Deep Spatial-Temporal Graph Modeling </p>
                <p class="fw-light lh-1"> IJCAI 2019</p>
                <span class="badge bg-success">Flow Prediction</span>
                <span class="badge bg-secondary">CNN and GCN</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The paper proposes a graph convolution layer with a self-adaptive adjacency matrix. 
                    The output comes from three parts: the forward and backward (for directed graphs) diffusion process of graph signals and the one from the self-adaptive adjacency matrix. 
                    This matrix is calculated by multiplying source and target embeddings with ReLU activation and SoftMax normalization. 
                    Apart from that, it also adopts stacked dilated casual convolutions to capture long temporal dependencies, which is called as temporal convolution layer. 
                    The key is the exponentially growing receptive field.
                    This part is also gated to control the information flow. 
                    Overall, the training purpose is the minimization of mean absolute error.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The self-adaptive matrix is impressive, which unifies the solution of problems with and without graph structures. 
                    It also solves the constraint of application of graph convolution network on dynamic graphs (as it needs the adjacency matrix). 
                    Nevertheless, I think the sum of three parts may not be able to summarize the correct answer. 
                    The weighted sum may be a better choice.
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Representing Urban Functions through Zone Embedding with Human Mobility Patterns </p>
                <p class="fw-light lh-1"> IJCAI 2018</p>
                <span class="badge bg-success">Land Use Prediction</span>
                <span class="badge bg-info text-dark">Embedding</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    Inspired by word2vec, the paper constructs zone embeddings from co-occurrences origin-destination zone, which are extracted from taxi trajectories. 
                    The writer uses the zone as a word and the corresponding departed/arrived zone-time event pair as the context. 
                    Moreover, the paper uses travel demand calculated from two factors, total arrival at destination zones and travel distance with the gravity model of transportation analysis, to assign weekday/weekend importance. 
                    The goal of the model is to minimize the importance-weighted difference between positive point-wise mutual information of co-occurrence and embedding decoded results. 
                    Regarding the evaluation, the paper utilizes k-means clustering to partition zone-set into urban function clusters. 
                    The prediction uses the proposed embedding vectors, while the validation employs vectors of percentage for different land use types in different zones. 
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The construction of co-occurrence pair is interesting. 
                    Division of the origin and destination to the event of one zone enables inclusion of timestamp and direction. 
                    The import of travel demand weight can make the embedding consider traffic-related factors. 
                    The usage of k-means cluster in evaluation part is also a brilliant idea to test embeddings. 
                    However, it might be not effective sometimes, as the percentage may not elucidate the actual function of one zone. 
                    In addition, some zone may have several functions with different importance, so the clustering will neglect other function with minor importance, rendering the result not comprehensive.
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Improving Land Use Classification using Human Mobility-based Hierarchical Place Embeddings </p>
                <p class="fw-light lh-1"> PerCom 2021</p>
                <span class="badge bg-success">Trajectory Prediction</span>
                <span class="badge bg-info text-dark">Embedding</span>
                <span class="badge bg-secondary">RNN</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    As the data sparsity may deteriorate the performance of location embeddings, the paper makes use of spatial hierarchical information. 
                    They use the LSTM-based RNN for next place prediction tasks and get the by-product embeddings for locations, which is in the region form. 
                    The main contribution is to design the dimension of the embedding and divide different dimensions to different size regions hierarchically. 
                    Finally, the paper uses the land use dataset for a prediction task to test the performance.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    In my opinion, hierarchical spatial embedding is an interesting idea, as we can generate embedding for different levels at one time. 
                    The discussion of the dimension division is also valuable. 
                    However, the model structure is just a normal RNN and nothing special is done for embedding generation, which may lead to the confusion about the effectiveness. 
                    Also, the simple and direct division of the embedding may be doubtful as the hierarchical information tend to be more complicated, not applicable in the simple space.
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Location Embeddings for Next Trip Recommendation </p>
                <p class="fw-light lh-1"> WWW 2019</p>
                <span class="badge bg-success">Next Location Prediction</span>
                <span class="badge bg-info text-dark">Embedding</span>
                <span class="badge bg-secondary">GCN and Recommendation System</span>
                <span class="badge bg-warning text-dark">Multimodal</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The task of the paper is to recommend cities for travelers, which can be seen as a binary classification task. 
                    First, the model constructs knowledge graph and learns the representation of cities from Wikipedia (by TF-IDF weighted sum of word vectors) and location-based social network data (by TransE). 
                    Then, the paper combines two existing recommender systems and learns user behaviors from their booking histories that also include personal profiles. 
                    All parts above are combined as a deep component. 
                    Another component is a feature factorization machines component with contextual information. 
                    These two components are concatenated together to feed into a multilayer perceptron. 
                    In the data preprocessing, they use a trained classifier to select leisure trips and only keep travels who have destinations over a threshold in their history.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The structure of the paper is elegant. 
                    The writer implements several existing approaches to construct the model, so it may be necessary to read related papers to understand it. 
                    This work is mainly related to the recommend system and the research level is city so that the contextual information is easy to collect. 
                    However, for our human mobility problems, the resolution may not be enough and most information are not available.
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> STUaNet: Understanding Uncertainty in Spatiotemporal Collective Human Mobility </p>
                <p class="fw-light lh-1"> WWW 2021</p>
                <span class="badge bg-success">Trajectory Prediction</span>
                <span class="badge bg-info text-dark">Uncertainty</span>
                <span class="badge bg-secondary">RNN, GCN and Recommendation System</span>
                <span class="badge bg-warning text-dark">Multimodal</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    This paper focuses on variation for human mobility predictions and quantifies uncertainty of internal data quality and external contextual interactions. 
                    The model includes two parts: human mobility prediction tasks and uncertainty learning tasks. 
                    For one, mobility prediction is backboned by graph convolution module within an LSTM. 
                    For next-interval predictions, the paper considers three scales: nearest intervals, same intervals in most recent days, average mobility intensity of the same intervals in each day of the last week. 
                    They use gravity-based model to indicate transition patterns from urban mobility flow. 
                    Another module uses the same input to quantify uncertainties for internal spatiotemporal dependencies and external context influence. 
                    On the one hand, period-wise sequence similarities are computed to estimate data quality. 
                    On the other hand, factorization machine (for contextual interactions) and graph convolution network(for spatial dependency) are used to compute external factors and learn mapping functions from different contextual factors to region-level uncertainty. 
                    Moreover, the model actively injects controllable Gaussian noise for guidance, with two weak supervised indicators: data quality estimation results and variance. 
                    In addition, a gated-based bridge is used to reduce learned uncertainty from predictions.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    The paper offers a special perspective for human mobility predictions. 
                    Uncertainty can make prediction results variate a lot under different data or settings. 
                    Thus, it is essential to consider it. 
                    The paper develops a seamless structure for both internal and external uncertainty estimations. 
                    Nonetheless, all calculators are neural networks and uncertainty labels are results from neural estimators and statistical variation, which may be not powerful and sometimes difficult to find an accurate results. 
                    More studies are needed for the ground-truth labels for uncertainty, in my opinion.
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Origin-Destination Matrix Prediction via Graph Convolution: a New Perspective of Passenger Demand Modeling </p>
                <p class="fw-light lh-1"> SIGKDD 2019</p>
                <span class="badge bg-success">OD/Flow Prediction</span>
                <span class="badge bg-secondary">LSTM and GCN</span>
                <span class="badge bg-info text-dark">Embedding</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    This paper predicts origin-destination matrix from taxi ride-hailing datasets. 
                    The authors aggregate features like graph message passing and put them into LSTM models. 
                    To solve the problem of data sparsity, which makes straightforward application of GCN infeasible, the paper considers geographical neighbors (from first law of geography) and semantic neighbors (from OD matrix). 
                    The grid will aggregate information of these two neighbors by concatenating two vectors. 
                    Instead of training embeddings, the paper trains the weight matrix in the aggregation function to select feature information.
                    Moreover, before aggregation, they pre-weight two neighbors according to the distance and the total number of demands. 
                    The sequential grid vector representations are fed into a period-skip LSTM to incorporate temporal information of passenger demands. 
                    The main task of the paper is to predict the OD matrix using grid embeddings via a transition matrix. 
                    Based on the proposed grid embeddings, the paper also conducts two subtasks for prediction of number of incoming and outgoing demands in each grid at different time slots. 
                    The loss includes abovementioned three parts.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    This paper proposes interesting concepts of geographical and semantics neighbors and use pre-weighted factors as a kind of prior knowledge to aggregate them. 
                    It is a great idea to introduce spatial features into a general graph. 
                    In my opinion, the main backbone of the model is mainly the LSTM, and the paper derives hidden states from message-like features. 
                    In addition, the subtasks somehow overlap the main task, as we can calculate the incoming and outgoing volumes from OD matrix.
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-5 justify-content-center">
            <div class="col-9">
                <p class="fs-3 fw-normal"> Predicting Origin-Destination Flow via Multi-Perspective Graph Convolutional Network </p>
                <p class="fw-light lh-1"> ICDE 2020</p>
                <span class="badge bg-success">OD/Flow Prediction Prediction</span>
                <span class="badge bg-secondary">LSTM and GCN</span>
                <span class="badge bg-info text-dark">Embedding</span>

                <br></br>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    This paper uses an LSTM and multiple convolution graphs to predict OD matrix at the next time step. 
                    First, the paper treats each OD pair individually (Intra-Region). 
                    It extracts five historical values (one week ago, one day ago and the three most recent time slots) and feeds them into an LSTM to obtain the initial hidden vector for OD pairs. 
                    Besides, the author uses 24-hour traffic volumes averaged by different days and calculates cosine correlation between two origins and two destinations. 
                    The result is used as features. 
                    Then, three different graphs are constructed (Between-Region): one dynamic graph via historical OD flows and two static graphs including adjacency graph via geographic information and POI graph via POI information. 
                    It conducts GCN for both origins and destinations to obtain a 2D GCN and uses a linear regression to get predicted traffic matrix. 
                    Three graphs are separately trained and the prediction is the average of them.
                </p>

                <p class="text-body fw-light lh-3" style="text-align: justify">
                    Due to the length of the paper, the LSTM part is not quite clear. 
                    The idea of three graphs is interesting and reasonable. One possible disadvantage is that the grid size is large(~3km) and they only consider usually non-zero OD pairs. 
                    It may lose information if we neglect some zero OD pairs. 
                    Moreover, I am doubtful about the idea of more layers to consider more hops of neighbors as it will cause over-smoothing problems.        
                </p>
            </div>
        </div>
    
        <hr style="width: 75%;">

        <div class="row py-1 justify-content-center">
            <div class="col-9">
                <figure class="text-end">
                      <p class="fw-light lh-1">Last updated: May 6, 2022</p>
                </figure>
            </div>
        </div>


    </div>


    <footer class="mt-5 text-white-50 text-center">
        <span class="text-muted">
            <p>
                <a href="https://cn.linkedin.com/in/mingfei-cai-23b172186" class="text-decoration-none">
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16">
                        <path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z"></path>
                    </svg>
                </a>
                |
                <a href="https://sekilab.iis.u-tokyo.ac.jp" class="text-decoration-none">
                    <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-link" viewBox="0 0 16 16">
                        <path d="M6.354 5.5H4a3 3 0 0 0 0 6h3a3 3 0 0 0 2.83-4H9c-.086 0-.17.01-.25.031A2 2 0 0 1 7 10.5H4a2 2 0 1 1 0-4h1.535c.218-.376.495-.714.82-1z"/>
                        <path d="M9 5.5a3 3 0 0 0-2.83 4h1.098A2 2 0 0 1 9 6.5h3a2 2 0 1 1 0 4h-1.535a4.02 4.02 0 0 1-.82 1H12a3 3 0 1 0 0-6H9z"/>
                    </svg>
                </a>            
            </p>
        </span>
        <span class="text-muted py-3">       
            <p class="small"> Copyright © 2022 Mingfei Cai. All Rights Reserved.</p>
        </span>
    </footer>
</div>


<!-- Optional JavaScript -->
<!-- Separate Popper and Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.10.2/dist/umd/popper.min.js" integrity="sha384-7+zCNj/IqJ95wo16oMtfsKbZ9ccEh31eOz1HGyDuCQ6wgnyJNSYdrPa03rtR1zdB" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.min.js" integrity="sha384-QJHtvGhmr9XOIpI6YVutG+2QOK9T+ZnN4kzFN1RtK3zEFEIsxhlmWl5/YESvpZ13" crossorigin="anonymous"></script>
</body>
</html>
